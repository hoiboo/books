---
layout: book
page_previous: part0080.html
index_page: ../index.html
page_next: part0082.html
styles: ["../page_styles.css","../stylesheet.css"]
---

<p class="calibre1">
<span class="calibre2">
<span class="bold">后见之明的社会成本</span>
</span>
</p>
<p class="calibre18">将从前的事编成叙事故事的大脑区域是构建意义的器官。当一件不可预知的事情发生时，我们会立即调整自己的世界观以适应这种意外。试想自己正在看一场足球赛，比赛双方的输赢记录相同。现在比赛结束了，其中一方击败了另一方。在你修正过的世界观里，赢得比赛的球队比输掉比赛的球队更加强大，你对过去和将来的看法也已经被这种新感觉改变了。从各种意外事件中积累经验的做法值得一试，但这样做也可能会导致一些危险后果。</p>
<p class="calibre13">人类大脑的常规局限使它没有足够的能力重构过去的知识结构或信念。一旦接受了一种新的世界观（或对世界某一方面的看法发生了变化），你就会立即丧失很大一部分回忆能力，无法回想起自己观点改变之前的那些想法了。</p>
<p class="calibre13">很多心理学家曾经研究过人们观念发生改变时究竟发生了什么这一问题。实验人员选了一个尚无定论的话题，比如说死刑，之后他们仔细测试了受试者的态度。接下来，受试者们会看见或听见一则颇具说服力的信息，这则信息对所选话题持或赞同或否定的态度。然后实验人员再次测试受试者的态度，受试者往往倾向于他们看到或听到的那个观点。最后，受试者要说出自己在实验前的观点。这项任务也许很难。受试者被问到之前的观点时，说的往往就是现在的观点，这便体现了替代理论，而且很多人都无法相信他们之前的观点与现在的不同。</p>
<p class="calibre13">你无法重构过去的想法，这种情况会不可避免地导致你低估自己受往事影响的程度。巴鲁克。费斯科霍夫率先揭示了“我早就知道”效应，或者说“后见之明”现象，当时他还在耶路撒冷读书。在尼克松1972年访问中国和苏联之前，费斯科霍夫和鲁斯。贝斯（我们的另一名学生）作了一项调查。受试者需要对尼克松此次外交破冰之行中可能出现的15种结果的可能性作出评估。毛泽东会同意与尼克松会面吗？美国会在外交上承认中国吗？眈眈相向几十年之后，美国还会和苏联就重大问题达成共识吗？</p>
<p class="calibre13">尼克松访问结束后，费斯科霍夫和贝斯让这些人回想他们对15个可能出现的结果的预测。结果很明显。如果一个事件果真发生了，人们就会夸大自己此前作出的预测的可能性；如果可能的事件并未发生，受试者就会错误地回忆说自己当初一直都认为此事发生的可能性不大。接下来的多次实验表明，人们不仅会高估自己最初的预测，还会高估其他人作出的预测。引起公众注意的其他事件中也出现了相似结果，例如辛普森谋杀案和比尔。克林顿总统的弹劾事件。根据发生过的事来改变个人的想法会产生深刻的认知错觉。</p>
<p class="calibre13">后见之明的偏见对决策者的评估行为有着恶劣影响，它导致观察者不是根据判断过程的合理性来评估一个判断的好坏，而是以结果的好坏作为判断标准。假设有一个低风险的外科手术，手术期间发生了一件始料未及的事故，病人因此死亡。事后，陪审团更倾向于相信手术本来就存在风险，而且主刀医生应该比其他人更清楚这一点。即使在制定决策时其想法是合理的，这一结果偏见也会使人们几乎不可能对他的决策作出正确评估。</p>
<p class="calibre13">后见之明对那些决策制定者而言尤其无情，他们的工作就像是为他人做代理人，这些人包括医生、金融顾问、三垒教练、执行总裁、社工、外交家以及政治家等。好的决策如果产生了坏的结果，我们就会责备那些决策制定者；而对那些只是在事后才能明确看出是正确的决策而言，其制定者也不会因此得到什么赞扬。这便是典型的“结果偏见”。若结果很糟糕，客户常会责备代理人没有看清墙上的笔迹—却忘了这笔迹原是用隐形墨水写成的，只有在事后才能变得清晰可辨。事前原本感觉很是谨慎的行动在事后也会被看成是不负责任的过失。曾经有一项以一个真实法律案例为基础的实验，实验人员问加利福尼亚大学的学生，明尼苏达州的德卢斯市是否应该花一大笔钱租用一个全天候大桥监控器来监视桥体，防止出现瓦砾阻塞河流的风险。其中一组学生只是看了该市做决策时的已有材料，其中24%的学生就认为德卢斯市应该承担租用洪水监控器的花销。第二组受试者则被告知瓦砾已经阻塞了河流，并引起了重大洪灾。尽管实验人员已经明确告诉他们不要让后见之明妨碍自己的判断，但这组中仍有56%的学生认为该市应该租用监控器。</p>
<p class="calibre13">结果越糟糕，后见之明的偏见就越严重。遇有重大灾难发生时，比如“9•11”恐怖袭击事件，我们尤其容易相信那些没能预见到这场灾难的官员玩忽职守，置公民安全于不顾。2001年7月10日，中央情报局得到消息：基地组织可能正在谋划一次针对美国的重大袭击。时任中央情报局局长的乔治·特尼特（George Tenet）并没有把这则消息传达给总统乔治·W·布什，而是告知了国家安全顾问康多莉扎·赖斯（Condoleezza Rice）。当事实浮出水面之后，《华盛顿邮报》的传奇编辑本·布莱德里（Ben Bradlee）表示，“如果你对即将主宰历史的事件有所了解的话，也许就有机会直接登上总统宝座了，我认为就是这么简单”。但在7月10日这天，没有人知道—或者说有可能知道—这则消息最终会在历史上留下重重的一笔。</p>
<p class="calibre13">很难在事后评论人们是否严格依照标准运作过程行事，因此那些希望自己的决定能经受住后见之明检测的决策制定者只好采用官僚的做派—极不情愿冒风险。由玩忽职守引起的起诉变得越来越常见，内科医生们以多种方式改变了自己的诊疗程序：要求患者作更多检查，请教专家更多病例，采用保守疗法，即使这些方法未必奏效也要用。这些行为与其说对病人有益，倒不如说是保护了医生，埋下了利益冲突的隐患。不断增强的责任可谓福祸参半。</p>
<p class="calibre13">尽管后见之明和结果偏见总会有滋生风险之嫌，却也会给那些不负责任的冒险者带来不应得的回馈，例如某位将军或企业家一次疯狂的冒险举动竟然成功了。那些一直很幸运的领导者不但从未因冒太大的风险而受到惩罚，相反，人们总会相信他们有很强的鉴别力和先见之明，能够预见成功；而那些曾经怀疑过他们的明智的人事后也会被视为平庸、胆小、懦弱之辈。几次幸运的冒险便会给一个不顾后果的领导人罩上耀眼的光环：极富远见、英勇果敢。</p>
<div class="mbppagebreak" id="calibre_pb_81"></div>
